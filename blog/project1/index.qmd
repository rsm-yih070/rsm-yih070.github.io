---
title: "A Replication of Karlan and List (2007)"
author: "Yiwei(Jerry) Huang"
date: today
callout-appearance: minimal # this hides the blue "i" icon on .callout-notes
---


## Introduction

Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the _American Economic Review_ in 2007. The article and supporting data are available from the [AEA website](https://www.aeaweb.org/articles?id=10.1257/aer.97.5.1774) and from Innovations for Poverty Action as part of [Harvard's Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/27853&version=4.2).


This project seeks to replicate their results.


## Data

### Description

_I begin by reading the dataset into Python and generating descriptive statistics to understand its structure._

```{python}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pyrsm as rsm
df = pd.read_stata(r"karlan_list_2007.dta")
df.describe()

```

:::: {.callout-note collapse="true"}
### Variable Definitions

| Variable             | Description                                                         |
|----------------------|---------------------------------------------------------------------|
| `treatment`          | Treatment                                                           |
| `control`            | Control                                                             |
| `ratio`              | Match ratio                                                         |
| `ratio2`             | 2:1 match ratio                                                     |
| `ratio3`             | 3:1 match ratio                                                     |
| `size`               | Match threshold                                                     |
| `size25`             | \$25,000 match threshold                                            |
| `size50`             | \$50,000 match threshold                                            |
| `size100`            | \$100,000 match threshold                                           |
| `sizeno`             | Unstated match threshold                                            |
| `ask`                | Suggested donation amount                                           |
| `askd1`              | Suggested donation was highest previous contribution                |
| `askd2`              | Suggested donation was 1.25 x highest previous contribution         |
| `askd3`              | Suggested donation was 1.50 x highest previous contribution         |
| `ask1`               | Highest previous contribution (for suggestion)                      |
| `ask2`               | 1.25 x highest previous contribution (for suggestion)               |
| `ask3`               | 1.50 x highest previous contribution (for suggestion)               |
| `amount`             | Dollars given                                                       |
| `gave`               | Gave anything                                                       |
| `amountchange`       | Change in amount given                                              |
| `hpa`                | Highest previous contribution                                       |
| `ltmedmra`           | Small prior donor: last gift was less than median \$35              |
| `freq`               | Number of prior donations                                           |
| `years`              | Number of years since initial donation                              |
| `year5`              | At least 5 years since initial donation                             |
| `mrm2`               | Number of months since last donation                                |
| `dormant`            | Already donated in 2005                                             |
| `female`             | Female                                                              |
| `couple`             | Couple                                                              |
| `state50one`         | State tag: 1 for one observation of each of 50 states; 0 otherwise  |
| `nonlit`             | Nonlitigation                                                       |
| `cases`              | Court cases from state in 2004-5 in which organization was involved |
| `statecnt`           | Percent of sample from state                                        |
| `stateresponse`      | Proportion of sample from the state who gave                        |
| `stateresponset`     | Proportion of treated sample from the state who gave                |
| `stateresponsec`     | Proportion of control sample from the state who gave                |
| `stateresponsetminc` | stateresponset - stateresponsec                                     |
| `perbush`            | State vote share for Bush                                           |
| `close25`            | State vote share for Bush between 47.5% and 52.5%                   |
| `red0`               | Red state                                                           |
| `blue0`              | Blue state                                                          |
| `redcty`             | Red county                                                          |
| `bluecty`            | Blue county                                                         |
| `pwhite`             | Proportion white within zip code                                    |
| `pblack`             | Proportion black within zip code                                    |
| `page18_39`          | Proportion age 18-39 within zip code                                |
| `ave_hh_sz`          | Average household size within zip code                              |
| `median_hhincome`    | Median household income within zip code                             |
| `powner`             | Proportion house owner within zip code                              |
| `psch_atlstba`       | Proportion who finished college within zip code                     |
| `pop_propurban`      | Proportion of population urban within zip code                      |

::::


### Balance Test 

As an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.

_I test whether the treatment and control groups differ on pre-treatment variables like mrm2 (months since last donation) using both a t-test and a linear regression. Both methods give the same result: no significant difference. This confirms that the groups are balanced, as also shown in Table 1 of the paper._

### "mrm2"
```{python}
treat = df[df['treatment'] == 1]['mrm2']
control = df[df['treatment'] == 0]['mrm2']

mean_treat = treat.mean()
mean_control = control.mean()
var_treat = treat.var(ddof=1)
var_control = control.var(ddof=1)
n_treat = treat.count()
n_control = control.count()

numerator = mean_treat - mean_control
denominator = np.sqrt(var_treat / n_treat + var_control / n_control)
t_stat = numerator / denominator

print("Mean Treatment:", round(mean_treat,3))
print("Std Treatment:", round(np.sqrt(var_treat),3))

print("Mean Control:", round(mean_control,3))
print("Std Control:", round(np.sqrt(var_control),3))
print("Overall Mean:", round(df['mrm2'].mean(),3))
print("Overall Std:", round(df['mrm2'].std(),3))
print("t test:", t_stat)

```

```{python}
model = rsm.model.regress(data = df, rvar = 'mrm2', evar = 'treatment')
model.summary()
```

The manual t-test and linear regression results for mrm2 (months since last donation) show no statistically significant difference between the treatment and control groups (t ≈ 0.12, p ≈ 0.905), indicating that this key pre-treatment variable is well balanced. This supports the validity of the random assignment and confirms that the experimental groups are comparable before the intervention. Table 1 is included in the paper to show that randomization produced balanced groups across a wide range of covariates, ensuring that any observed differences in outcomes can be attributed to the treatment rather than pre-existing differences.

### "hpa"
```{python}
treat = df[df['treatment'] == 1]['hpa']
control = df[df['treatment'] == 0]['hpa']

mean_treat = treat.mean()
mean_control = control.mean()
var_treat = treat.var(ddof=1)
var_control = control.var(ddof=1)
n_treat = treat.count()
n_control = control.count()

numerator = mean_treat - mean_control
denominator = np.sqrt(var_treat / n_treat + var_control / n_control)
t_stat = numerator / denominator

print("Mean Treatment:", round(mean_treat,3))
print("Std Treatment:", round(np.sqrt(var_treat),3))

print("Mean Control:", round(mean_control,3))
print("Std Control:", round(np.sqrt(var_control),3))
print("Overall Mean:", round(df['hpa'].mean(),3))
print("Overall Std:", round(df['hpa'].std(),3))
print("t test:", t_stat)
```

```{python}
model = rsm.model.regress(data = df, rvar = 'hpa', evar = 'treatment')
model.summary()
```

The hpa variable is a pre-treatment covariate, so the lack of a significant difference across groups provides evidence that random assignment was successful. In particular, it suggests that prior donation behavior (as measured by the highest past contribution) was balanced across the treatment and control conditions. This supports the validity of any causal claims made later in the experiment, as we can reasonably assume that any post-treatment differences in donation behavior are due to the treatment itself rather than pre-existing differences in donor generosity.

### "freq"
```{python}
treat = df[df['treatment'] == 1]['freq']
control = df[df['treatment'] == 0]['freq']

mean_treat = treat.mean()
mean_control = control.mean()
var_treat = treat.var(ddof=1)
var_control = control.var(ddof=1)
n_treat = treat.count()
n_control = control.count()

numerator = mean_treat - mean_control
denominator = np.sqrt(var_treat / n_treat + var_control / n_control)
t_stat = numerator / denominator

print("Mean Treatment:", round(mean_treat,3))
print("Std Treatment:", round(np.sqrt(var_treat),3))

print("Mean Control:", round(mean_control,3))
print("Std Control:", round(np.sqrt(var_control),3))
print("Overall Mean:", round(df['freq'].mean(),3))
print("Overall Std:", round(df['freq'].std(),3))
print("t test:", t_stat)
```

```{python}
model = rsm.model.regress(data = df, rvar = 'freq', evar = 'treatment')
model.summary()
```

The variable freq, representing the number of prior donations, shows nearly identical means between the treatment and control groups. Both the manual t-test and regression confirm that this difference is not statistically significant. This suggests that random assignment successfully balanced this pre-treatment characteristic, which supports the internal validity of the experimental design. Because the treatment and control groups are statistically equivalent in terms of donation frequency history, we can be more confident that any observed post-treatment effects on donation behavior are attributable to the treatment rather than pre-existing differences in donor activity.

## Experimental Results

### Charitable Contribution Made

First, I analyze whether matched donations lead to an increased response rate of making a donation. 

_I create a barplot showing the proportion of people who donated in each group. One bar represents the treatment group and the other represents the control group, allowing for a visual comparison of donation rates._

```{python}
prop_donated = df.groupby('treatment')['gave'].mean().reset_index()
prop_donated['group'] = prop_donated['treatment'].map({0: 'Control', 1: 'Treatment'})

sns.barplot(data=prop_donated, x='group', y='gave')
plt.ylabel("Proportion Who Donated")
plt.title("Donation Rate by Group")
plt.show()
```

_I run a t-test and a linear regression to compare donation rates between treatment and control. Both show that the treatment group is more likely to donate. This suggests that people respond to matching offers by being more willing to give._

```{python}
treat = df[df['treatment'] == 1]['gave']
control = df[df['treatment'] == 0]['gave']

mean_diff = treat.mean() - control.mean()
var_treat = treat.var()
var_control = control.var()
n_treat = len(treat)
n_control = len(control)

t_stat = mean_diff / np.sqrt(var_treat / n_treat + var_control / n_control)
print("T-statistic:", t_stat)
```

```{python}
model = rsm.model.regress(data = df, rvar = 'gave', evar = 'treatment')
model.summary()
```

The statistical analysis shows that individuals who received the treatment — a matching donation offer — were significantly more likely to make a charitable contribution compared to those who received the control letter. Both the t-test and linear regression indicate that this difference is unlikely to be due to chance. This suggests that the presence of a matching grant acts as a powerful motivator, nudging people toward taking action. In the context of human behavior, this reveals that even a subtle change in framing — like knowing one's gift will be matched — can meaningfully increase the likelihood of giving. It highlights how social cues or perceived amplification of impact can influence decision-making in charitable contexts.


_I run a probit regression of donation on treatment assignment. The results replicate Table 3, column 1 in the paper, showing a positive and significant effect of treatment on the likelihood of donating._

```{python}
from statsmodels.discrete.discrete_model import Probit

probit_model = Probit.from_formula('gave ~ treatment', data=df)
probit_result = probit_model.fit()
print(probit_result.summary())
mfx = probit_result.get_margeff()
print(mfx.summary())
```

### Differences between Match Rates

Next, I assess the effectiveness of different sizes of matched donations on the response rate.

_I run t-tests comparing donation rates between different match ratios (1:1, 2:1, 3:1). The results show no significant differences, suggesting that larger match ratios do not increase donation likelihood. This supports the authors' comment that higher match rates don’t have additional impact beyond offering a match._

```{python}
# t-test between 2:1 and 1:1 ratios
gave_1_1 = df[df['ratio'] == 1]['gave']
gave_2_1 = df[df['ratio'] == 2]['gave']

from scipy.stats import ttest_ind
t_stat, p_val = ttest_ind(gave_2_1, gave_1_1, equal_var=False)

print("2:1 vs 1:1 Match Rate:")
print(f"T-stat: {t_stat:.3f}, P-value: {p_val:.3f}")
```

```{python}
# t-test between 3:1 and 1:1 ratios
gave_3_1 = df[df['ratio'] == 3]['gave']
gave_1_1 = df[df['ratio'] == 1]['gave']

t_stat, p_val = ttest_ind(gave_3_1, gave_1_1, equal_var=False)
print("3:1 vs 1:1 Match Rate:")
print(f"T-stat: {t_stat:.3f}, P-value: {p_val:.3f}")
```

```{python}
# t-test between 3:1 and 2:1 ratios
gave_3_1 = df[df['ratio'] == 3]['gave']
gave_2_1 = df[df['ratio'] == 2]['gave']

t_stat, p_val = ttest_ind(gave_3_1, gave_2_1, equal_var=False)
print("3:1 vs 2:1 Match Rate:")
print(f"T-stat: {t_stat:.3f}, P-value: {p_val:.3f}")
```

My results clearly support the authors' conclusion: while higher match ratios may show slightly higher donation rates numerically, those differences are not statistically significant, and therefore do not provide strong evidence that larger match sizes are more effective than 1:1 matches.


_I run a regression of gave on the match ratio indicators. The coefficients are small, and only the 2:1 and 3:1 ratios are statistically significant, but the differences between them are minimal. This suggests that while offering a match matters, increasing the match size has little additional effect._

```{python}
model = rsm.model.regress(data = df, rvar = 'gave', evar = 'ratio')
model.summary()
```

Regression results show that all three match ratios (1:1, 2:1, 3:1) are associated with slightly higher donation rates compared to the control group, but the differences are small. The coefficient for ratio[1] (1:1 match) is 0.003 and marginally significant (p = 0.097), while the coefficients for ratio[2] (2:1) and ratio[3] (3:1) are both 0.005 and statistically significant at the 1% level (p = 0.006 and p = 0.005). However, the differences between them are not large in magnitude — all are within 0.002 of each other — suggesting that although offering any match tends to increase donations, there is little evidence that larger match sizes lead to proportionally greater increases. This supports the conclusion that the presence of a match matters more than its generosity, and that people are generally responsive to the signal of support, not necessarily the size of the match.

_I calculate the response rate differences both directly from the data and using regression coefficients. The difference between 1:1 and 2:1 is small, and there is no difference between 2:1 and 3:1. This suggests that increasing the match ratio does not meaningfully improve donation rates._

```{python}
p_1_1 = df[df['ratio'] == 1]['gave'].mean()
p_2_1 = df[df['ratio'] == 2]['gave'].mean()
p_3_1 = df[df['ratio'] == 3]['gave'].mean()

print("Response rates:")
print(f"1:1 = {p_1_1*100:.3f}%, 2:1 = {p_2_1*100:.3f}%, 3:1 = {p_3_1*100:.3f}%")
```

Differences (From Regression Coefficients):

2:1 − 1:1 = 0.005 − 0.003 = 0.002

3:1 − 2:1 = 0.005 − 0.005 = 0.000


Both the raw response rates and regression coefficients indicate that increasing the match from 1:1 to 2:1 produces a small increase in the probability of donating (about 0.2 percentage points), while moving from 2:1 to 3:1 shows virtually no change. These differences are very modest in size, and the lack of improvement from 2:1 to 3:1 suggests diminishing returns to increasing match generosity. The findings reinforce the conclusion that offering any match increases donations, but offering a larger match ratio does not lead to proportionally greater giving. The signal of a match itself may be more powerful than the actual amount matched.

### Size of Charitable Contribution

In this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.

_I run a t-test and a regression of donation amount on treatment. The treatment group gives slightly more on average, but the difference is only marginally significant. This suggests that the treatment mainly increases the number of donors, not the amount they give._

```{python}
model = rsm.model.regress(data = df, rvar = 'amount', evar = 'treatment')
model.summary()
```

From this analysis, we learn that individuals who received the matching grant treatment donated slightly more on average than those in the control group, but the difference is only marginally statistically significant (p = 0.063). The treatment effect estimate suggests that the treatment group gave about 15 cents more per person than the control group, which is a small increase. This result implies that the primary effect of the matching grant is likely driven by increasing the number of people who give, rather than substantially increasing the donation amounts of those who would already have donated. It highlights that while the match offer motivates more people to donate, it doesn't strongly influence how much they give on average.

_I repeat the regression using only those who donated. The treatment has no significant effect on the amount given among donors. This means the treatment influences whether people donate, but not how much they give once they do. Since the sample is restricted to donors, the treatment effect here does not have a causal interpretation._

```{python}
model = rsm.model.regress(data = df[df['gave'] == 1], rvar = 'amount', evar = 'treatment')
model.summary()
```

The regression results show that among individuals who made a donation, the treatment group gave slightly less on average than the control group, but this difference (−1.67) is not statistically significant (p = 0.561). This tells us that the matching grant treatment did not affect the amount given by those who chose to donate. In other words, the presence of a match increased the number of people who gave, but not how much they gave once they decided to give.


As for causal interpretation: since this regression is limited only to people who donated, it suffers from selection bias — treatment may have influenced who donated, and the group of donors in treatment and control may differ in unobserved ways. Therefore, the treatment coefficient cannot be interpreted causally in this conditional regression. Only the earlier regression using the full sample (which preserves random assignment) supports a causal interpretation of treatment effects.

_I create two histograms showing the distribution of donation amounts among donors, one for the treatment group and one for the control group. Each plot includes a red vertical line indicating the group’s average donation. The distributions and averages are similar, showing that donation amounts are not affected by the treatment._

```{python}
donors = df[df['gave'] == 1]

fig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)
sns.histplot(donors[donors['treatment'] == 0]['amount'], bins=30, ax=axes[0], color='skyblue')
axes[0].axvline(donors[donors['treatment'] == 0]['amount'].mean(), color='red', linestyle='--')
axes[0].set_title('Control Group')
axes[0].set_xlabel('Donation Amount')

sns.histplot(donors[donors['treatment'] == 1]['amount'], bins=30, ax=axes[1], color='lightgreen')
axes[1].axvline(donors[donors['treatment'] == 1]['amount'].mean(), color='red', linestyle='--')
axes[1].set_title('Treatment Group')
axes[1].set_xlabel('Donation Amount')

plt.tight_layout()
plt.show()
```

## Simulation Experiment

As a reminder of how the t-statistic "works," in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.

Suppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made. 

Further suppose that the true distribution of respondents who do get a charitable donation match of any size  is Bernoulli with probability p=0.022 that a donation is made.

### Law of Large Numbers

_I simulate 100,000 draws from the control group and 10,000 from the treatment group, then calculate a vector of 10,000 differences. I plot the cumulative average of these differences to visualize how it stabilizes over time. The plot shows that the cumulative average approaches the true difference in means, illustrating the Law of Large Numbers._

```{python}
n = 10000
p_control = 0.018
p_treatment = 0.022
true_diff = p_treatment - p_control 

control = np.random.binomial(1, p_control, n)
treatment = np.random.binomial(1, p_treatment, n)

diffs = treatment - control 

cumulative_avg = np.cumsum(diffs) / np.arange(1, n + 1)

plt.figure(figsize=(10, 5))
plt.plot(cumulative_avg, label='Cumulative Average Difference')
plt.axhline(true_diff, color='red', linestyle='--', label='True Difference = 0.004')
plt.title('Law of Large Numbers: Cumulative Average of Treatment - Control')
plt.xlabel('Number of Simulated Pairs')
plt.ylabel('Average Difference')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

```

The cumulative average of the difference in donation outcomes between the treatment and control groups begins with high variability but quickly stabilizes as more simulated pairs are added. By around 1,000–2,000 iterations, the average difference converges very closely to the true population difference of 0.004, shown by the red dashed line. This confirms that as the sample size increases, the sample average becomes a reliable and consistent estimator of the population average. In other words, the plot clearly shows that the cumulative average approaches the true difference in means, which is exactly what the Law of Large Numbers predicts.



### Central Limit Theorem

_I simulate 1,000 average differences between treatment and control groups at sample sizes of 50, 200, 500, and 1000. For each sample size, I plot a histogram of the average differences. At smaller sample sizes, the distribution is wider and zero is near the center, but as the sample size increases, the distribution becomes tighter and more normal-shaped, and zero shifts into the tail. This demonstrates the Central Limit Theorem and how larger samples make it easier to detect true differences._

```{python}
p_control = 0.018
p_treatment = 0.022
true_diff = p_treatment - p_control
n_sim = 1000
sample_sizes = [50, 200, 500, 1000]

fig, axes = plt.subplots(2, 2, figsize=(14, 10))
axes = axes.flatten()

for i, n in enumerate(sample_sizes):
    avg_diffs = []

    for _ in range(n_sim):
        control_sample = np.random.binomial(1, p_control, n)
        treatment_sample = np.random.binomial(1, p_treatment, n)
        diff = treatment_sample.mean() - control_sample.mean()
        avg_diffs.append(diff)
    
    sns.histplot(avg_diffs, bins=30, kde=True, stat="frequency", color="blue", ax=axes[i])
    axes[i].axvline(0, color='red', linestyle='--', linewidth=2)
    axes[i].set_title(f"Sample size = {n}", fontsize=14)
    axes[i].set_xlabel("Mean Difference (Treatment - Control)")
    axes[i].set_ylabel("Frequency")

plt.suptitle("Central Limit Theorem Simulation", fontsize=16, y=1.02)
plt.tight_layout()
plt.show()

```

In the histogram for a sample size of 50, the distribution is wide and irregular, and zero appears near the center — indicating that at this small sample size, it's still quite common to observe no difference between treatment and control groups due to random variation. As the sample size increases to 200 and 500, the distributions become more symmetric and bell-shaped, with zero gradually shifting away from the peak. By the time we reach a sample size of 1000, the distribution is tightly centered around a positive value, and zero clearly lies in the tail of the distribution. This shift demonstrates how larger samples improve our ability to detect even small differences and reduce the likelihood of falsely concluding that there’s no effect when one actually exists. In short, as sample size increases, zero moves from the middle toward the tails, confirming the predictions of the Central Limit Theorem and the increasing statistical power of larger samples.








